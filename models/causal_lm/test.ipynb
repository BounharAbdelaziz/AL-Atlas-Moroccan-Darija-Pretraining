{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/abounhar/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    pipeline, \n",
    "    AutoModel,\n",
    "    AutoModelForMaskedLM, \n",
    "    AutoTokenizer,\n",
    ")\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List, Union\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Set up matplotlib for Arabic text\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] = 'Arial'  # Or another font that supports Arabic\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Arial']  # Ensure Arabic characters display correctly\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"BounharAbdelaziz/xlm-roberta-large-bs-16-lr-0.0001-ep-1-wp-0.1-gacc-8-gnm-1.0-FP16-mx-512-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: BounharAbdelaziz/xlm-roberta-large-bs-16-lr-0.0001-ep-1-wp-0.1-gacc-8-gnm-1.0-FP16-mx-512-v0.1\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "print(f\"Loading model: {MODEL}\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Create masked language modeling pipeline\n",
    "mlm_pipeline = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_test_mlm(mlm_pipeline):\n",
    "    \"\"\"\n",
    "    Load a masked language model and test it on Moroccan Arabic examples.\n",
    "    Args:\n",
    "        model_name (str): HuggingFace model name/path\n",
    "    \"\"\"\n",
    "    \n",
    "    # Test examples in Moroccan Arabic\n",
    "    test_sentences = [\n",
    "        \"العاصمة د <mask> هي الرباط\",  # Hello, how are you?\n",
    "        \"المغرب <mask> زوين\",      # Good morning\n",
    "        \"انا سميتي مريم، و كنسكن ف<mask> العاصمة دفلسطين\"     # I am at home\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTesting model on Moroccan Arabic sentences:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for sentence in test_sentences:\n",
    "        results = mlm_pipeline(sentence, top_k=3)\n",
    "        \n",
    "        print(f\"\\nInput: {sentence}\")\n",
    "        print(\"Top 3 predictions:\")\n",
    "        for result in results:\n",
    "            print(f\"- {result['token_str']}: {result['score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"العاصمة د المغرب هي الرباط\",  # Hello, how are you?\n",
    "    \" المغرب بلاد زوين\",      # Good morning\n",
    "    \"انا سميتي مريم، و كنسكن فالقدس العاصمة دفلسطين\"     # I am at home\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing model on Moroccan Arabic sentences:\n",
      "--------------------------------------------------\n",
      "\n",
      "Input: العاصمة د <mask> هي الرباط\n",
      "Top 3 predictions:\n",
      "- المغرب: 0.964\n",
      "- المملكة: 0.007\n",
      "- الجزائر: 0.006\n",
      "\n",
      "Input: المغرب <mask> زوين\n",
      "Top 3 predictions:\n",
      "- بلاد: 0.781\n",
      "- بلد: 0.036\n",
      "- مكان: 0.031\n",
      "\n",
      "Input: انا سميتي مريم، و كنسكن ف<mask> العاصمة دفلسطين\n",
      "Top 3 predictions:\n",
      "- القدس: 0.771\n",
      "- القاهرة: 0.025\n",
      "- فلسطين: 0.025\n"
     ]
    }
   ],
   "source": [
    "load_and_test_mlm(mlm_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLMEmbedder:\n",
    "    def __init__(self, model_name: str = \"UBC-NLP/arabertv02-base\"):\n",
    "        \"\"\"\n",
    "        Initialize the MLM embedding model\n",
    "        Args:\n",
    "            model_name (str): HuggingFace model name/path\n",
    "        \"\"\"\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Load model without MLM head using AutoModel instead of AutoModelForMaskedLM\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(self.device).eval()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "    def get_embeddings(\n",
    "        self, \n",
    "        texts: Union[str, List[str]], \n",
    "        pooling_strategy: str = 'mean',\n",
    "        batch_size: int = 32\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for input texts\n",
    "        \n",
    "        Args:\n",
    "            texts: Single text or list of texts\n",
    "            pooling_strategy: How to combine token embeddings ('mean', 'cls', or 'max')\n",
    "            batch_size: Batch size for processing\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings\n",
    "        \"\"\"\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "            \n",
    "        all_embeddings = []\n",
    "        \n",
    "        # Process in batches\n",
    "        for i in tqdm(range(0, len(texts), batch_size)):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            \n",
    "            # Tokenize batch\n",
    "            encoded = self.tokenizer(batch_texts,\n",
    "                                   padding=True,\n",
    "                                   truncation=True,\n",
    "                                   max_length=512,\n",
    "                                   return_tensors='pt')\n",
    "            \n",
    "            # Move to device\n",
    "            input_ids = encoded['input_ids'].to(self.device)\n",
    "            attention_mask = encoded['attention_mask'].to(self.device)\n",
    "            \n",
    "            # Get model outputs\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(input_ids=input_ids,\n",
    "                                   attention_mask=attention_mask)\n",
    "                \n",
    "                # Get hidden states\n",
    "                hidden_states = outputs.last_hidden_state\n",
    "                \n",
    "                # Apply pooling strategy\n",
    "                if pooling_strategy == 'cls':\n",
    "                    # Use [CLS] token embedding\n",
    "                    embeddings = hidden_states[:, 0, :]\n",
    "                    \n",
    "                elif pooling_strategy == 'mean':\n",
    "                    # Mean pooling - take attention mask into account for averaging\n",
    "                    attention_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "                    sum_embeddings = torch.sum(hidden_states * attention_mask_expanded, 1)\n",
    "                    sum_mask = torch.clamp(attention_mask_expanded.sum(1), min=1e-9)\n",
    "                    embeddings = sum_embeddings / sum_mask\n",
    "                    \n",
    "                elif pooling_strategy == 'max':\n",
    "                    # Max pooling\n",
    "                    attention_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "                    hidden_states[attention_mask_expanded == 0] = -1e9  # Set padding tokens to large negative value\n",
    "                    embeddings = torch.max(hidden_states, 1)[0]\n",
    "                \n",
    "                # Move to CPU and convert to numpy\n",
    "                embeddings = embeddings.cpu().numpy()\n",
    "                all_embeddings.append(embeddings)\n",
    "        \n",
    "        # Concatenate all batches\n",
    "        final_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "        return final_embeddings\n",
    "    \n",
    "    def similarity(self, text1: str, text2: str, pooling_strategy: str = 'mean') -> float:\n",
    "        \"\"\"\n",
    "        Calculate cosine similarity between two texts\n",
    "        \"\"\"\n",
    "        # Get embeddings\n",
    "        emb1, emb2 = self.get_embeddings([text1, text2], pooling_strategy=pooling_strategy)\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "        return similarity\n",
    "    \n",
    "    def compute_similarity_matrix(self, texts: List[str], pooling_strategy: str = 'mean') -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute similarity matrix between all pairs of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of texts to compare\n",
    "            pooling_strategy: Pooling strategy for embeddings\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of shape (len(texts), len(texts)) containing similarities\n",
    "        \"\"\"\n",
    "        # Get embeddings for all texts\n",
    "        embeddings = self.get_embeddings(texts, pooling_strategy=pooling_strategy)\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "        embeddings_normalized = embeddings / norms\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity_matrix = np.dot(embeddings_normalized, embeddings_normalized.T)\n",
    "        \n",
    "        return similarity_matrix\n",
    "    \n",
    "    def plot_similarity_matrix(self, texts: List[str], pooling_strategy: str = 'mean',\n",
    "                             figsize: tuple = (12, 10), annot: bool = True):\n",
    "        \"\"\"\n",
    "        Plot similarity matrix as a heatmap with proper Arabic text handling\n",
    "        \n",
    "        Args:\n",
    "            texts: List of texts to compare\n",
    "            pooling_strategy: Pooling strategy for embeddings\n",
    "            figsize: Figure size for the plot\n",
    "            annot: Whether to annotate cells with numerical value\n",
    "        \"\"\"\n",
    "        similarity_matrix = self.compute_similarity_matrix(texts, pooling_strategy)\n",
    "        \n",
    "        # Create labels (keep full Arabic text, no truncation)\n",
    "        labels = texts.copy()  # Keep full text for Arabic\n",
    "        \n",
    "        # Create figure with Arabic-compatible settings\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Create heatmap with right-to-left text alignment\n",
    "        ax = sns.heatmap(similarity_matrix, \n",
    "                        annot=annot, \n",
    "                        fmt='.2f',\n",
    "                        cmap='coolwarm', \n",
    "                        xticklabels=labels,\n",
    "                        yticklabels=labels,\n",
    "                        vmin=-1, \n",
    "                        vmax=1)\n",
    "        \n",
    "        # Rotate xlabels for better readability\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        \n",
    "        # Adjust label properties for Arabic text\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontsize=10, ha='right')\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), fontsize=10, ha='right')\n",
    "        \n",
    "        plt.title(f'مصفوفة التشابه النصي ({pooling_strategy})', fontsize=12, pad=20)  # Arabic title\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at BounharAbdelaziz/xlm-roberta-large-bs-16-lr-0.0001-ep-1-wp-0.1-gacc-8-gnm-1.0-FP16-mx-512-v0.1 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings...\n",
      "\n",
      "Generating similarity matrix with mean pooling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical similarity matrix (mean pooling):\n",
      "[[0.99999994 0.99174446 0.9909823  0.98841196]\n",
      " [0.99174446 1.0000001  0.98677593 0.98960155]\n",
      " [0.9909823  0.98677593 0.9999999  0.9872966 ]\n",
      " [0.98841196 0.98960155 0.9872966  1.0000004 ]]\n",
      "\n",
      "Generating similarity matrix with cls pooling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical similarity matrix (cls pooling):\n",
      "[[1.         0.9968043  0.99470186 0.993513  ]\n",
      " [0.9968043  1.0000001  0.99329454 0.99404615]\n",
      " [0.99470186 0.99329454 1.0000001  0.9928244 ]\n",
      " [0.993513   0.99404615 0.9928244  1.        ]]\n",
      "\n",
      "Generating similarity matrix with max pooling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical similarity matrix (max pooling):\n",
      "[[1.0000001  0.97399235 0.9489736  0.95984066]\n",
      " [0.97399235 1.         0.9390589  0.9548985 ]\n",
      " [0.9489736  0.9390589  1.         0.9513192 ]\n",
      " [0.95984066 0.9548985  0.9513192  1.0000002 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedder\n",
    "embedder = MaskedLMEmbedder(MODEL)\n",
    "\n",
    "# Example texts (in Arabic)\n",
    "texts = [\n",
    "    \"العاصمة د المغرب هي الرباط\",  # Hello, how are you?\n",
    "    \" المغرب بلاد زوين\",      # Good morning\n",
    "    \"انا سميتي مريم، و كنسكن فالقدس العاصمة دفلسطين\",\n",
    "    \"سير تخرا ا داك لحمار\", # I am at home\n",
    "]\n",
    "\n",
    "# Get embeddings with different pooling strategies\n",
    "print(\"\\nGenerating embeddings...\")\n",
    "\n",
    "# Generate and plot similarity matrices for different pooling strategies\n",
    "for strategy in ['mean', 'cls', 'max']:\n",
    "    print(f\"\\nGenerating similarity matrix with {strategy} pooling...\")\n",
    "    # embedder.plot_similarity_matrix(texts, pooling_strategy=strategy)\n",
    "    \n",
    "    # Print numerical similarity matrix\n",
    "    sim_matrix = embedder.compute_similarity_matrix(texts, pooling_strategy=strategy)\n",
    "    print(f\"\\nNumerical similarity matrix ({strategy} pooling):\")\n",
    "    print(sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.98G/1.98G [00:53<00:00, 36.6MB/s]   \n",
      "tokenizer.json: 100%|██████████| 11.4M/11.4M [00:00<00:00, 34.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "def load_and_push(local_path, repo_id):\n",
    "    \n",
    "    # Load model and tokenizer\n",
    "    model = AutoModel.from_pretrained(local_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(local_path)\n",
    "    \n",
    "    # Push to hub\n",
    "    model.push_to_hub(repo_id)\n",
    "    tokenizer.push_to_hub(repo_id)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "falcon = \"/home/infres/abounhar/AtlasIA/to_my_github/Al-Atlas-Dataset/models/BounharAbdelaziz/Falcon3-1B-Base-bs-4-lr-0.0001-ep-2-wp-0.1-gacc-32-gnm-1.0-FP16-mx-2048-v0.1/checkpoint-7050\"\n",
    "qwen = \"/home/infres/abounhar/AtlasIA/to_my_github/Al-Atlas-Dataset/models/BounharAbdelaziz/Qwen2.5-0.5B-bs-4-lr-0.0001-ep-2-wp-0.1-gacc-32-gnm-1.0-FP16-mx-2048-v0.1/checkpoint-14550\"\n",
    "\n",
    "model_path = qwen\n",
    "model, tokenizer = load_and_push(\n",
    "    model_path,\n",
    "    \"atlasia/Al-Atlas-LLM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading model from: /home/infres/abounhar/AtlasIA/to_my_github/Al-Atlas-Dataset/models/BounharAbdelaziz/Qwen2.5-0.5B-bs-4-lr-0.0001-ep-2-wp-0.1-gacc-32-gnm-1.0-FP16-mx-2048-v0.1/checkpoint-14550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "falcon = \"/home/infres/abounhar/AtlasIA/to_my_github/Al-Atlas-Dataset/models/BounharAbdelaziz/Falcon3-1B-Base-bs-4-lr-0.0001-ep-2-wp-0.1-gacc-32-gnm-1.0-FP16-mx-2048-v0.1/checkpoint-7050\"\n",
    "qwen = \"/home/infres/abounhar/AtlasIA/to_my_github/Al-Atlas-Dataset/models/BounharAbdelaziz/Qwen2.5-0.5B-bs-4-lr-0.0001-ep-2-wp-0.1-gacc-32-gnm-1.0-FP16-mx-2048-v0.1/checkpoint-14550\"\n",
    "\n",
    "model_path = qwen\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create pipeline\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_path,\n",
    "    device=device,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    # \"العاصمة د المغرب\",  # Hello, how are you?\n",
    "    # \" المغرب بلاد زوين\",      # Good morning\n",
    "    # \"انا سميتي مريم، و كنسكن فالقدس العاصمة دفلسطين\",\n",
    "    # \"سير تخرا ا داك لحمار\", # I am at home\n",
    "    # \"الماكلة المغربية كتعتبر من أحسن الماكلات فالعالم\",\n",
    "    # \"قلب القدرة على فمها تشبه البنت\",\n",
    "    # \" عطينا شرح مفصل على كيفاش\",\n",
    "    # \"عطيني خمسة الأسماء ديال ممثلين مغاربة\",\n",
    "    \"الذكاء الاصطناعي هو فرع من علوم الكمبيوتر اللي كيركز \",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: الذكاء الاصطناعي هو فرع من علوم الكمبيوتر اللي كيركز گاع على تطوير الآلات اللي قادرة تدير مهام اللي عادة خاصها ذكاء بشري، بحال التعرف على الأنماط، حل المشاكل، اتخاذ القرارات، وفهم اللغة الطبيعية. الذكاء الاصطناعي عندو إمكانية باش يغير بزاف كيفاش كنعيشو، نخدمو، ونتفاعلو مع بعضياتنا.\n",
      "\n",
      "واحد من أهم التطبيقات ديال الذكاء الاصطناعي هو فالصحة. الذكاء الاصطناعي يقدر يعاون الطبة باش يشخصو الأمراض بدقة أكبر، يأوتوماتيزيو المهام الروتينية، ويحسنو نتائج المرضى. مثلا، الخوارزميات ديال الذكاء الاصطناعي تقدر تحلل الصور الطبية باش تكتاشف العلامات الحيوية اللي ممكن ما تكونش واضحة للفحص البشري. زيادة على هادشي، الذكاء الاصطناعي يقدر يعاون الأطباء باش يصاوبو خطط علاج مخصصة حسب الاحتياجات الخاصة ديال كل مريض.\n",
      "\n",
      "بالإضافة للصحة، الذكاء الاصطناعي عندو إمكانية باش يغير الطريقة اللي كنتفاعلو بيها مع التكنولوجيا. مثلا، الذكاء الاصطناعي يقدر يعاون الشركات باش يحسنو العمليات ديالهم، يأوتوماتيزيو المهام الروتينية، ويحسنو تجربة الزبون. زيادة على هادشي، الذكاء الاصطناعي يقدر يعاون الفلاحة باش يزيدو الإنتاجية، ينقصو التكاليف، ويحسنو جودة المحاصيل.\n",
      "\n",
      "فالختام، الذكاء الاصطناعي عندو إمكانية باش يغير بزاف كيفاش كنعيشو، نخدمو، ونتفاعلو مع بعضياتنا. من خلال تطوير أنظمة ذكاء اصطناعي متقدمة، نقدرو نحسنو الكفاءة، نحسنو جودة الحياة، ونخلقو عالم أحسن للأجيال الجاية. مع استمرار تطور الذكاء الاصطناعي، من المرجح أنه غادي يلعب دور أكثر أهمية فتشكيل مستقبل البشرية. فالنهاية، الذكاء الاصطناعي عندو إمكانية باش يغير بزاف كيفاش كنعيشو، نخدمو، ونتفاعلو مع بعضياتنا. ولكن، خاصنا نكونو واعيين بالمخاطر والتحديات المرتبطة بالذكاء الاصطناعي باش نستافدو منو بأحسن طريقة. فالنهاية، الذكاء الاصطناعي عندو إمكانية باش يغير بزاف كيفاش كنعيشو، نخدمو، ونتفاعلو مع بعضياتنا. ولكن، خاصنا نكونو واعيين بالمخاطر والتحديات المرتبطة بالذكاء الاصطناعي باش نستافدو منو بأحسن طريقة. فالنهاية، الذكاء الاصطناعي عندو إمكانية باش يغير بزاف كيفاش كنعيشو، نخدمو، ونتفاعلو مع بعضياتنا. ولكن، خاصنا نكونو واعيين بالمخاطر والتحديات المرتبطة بالذكاء الاصطناعي باش نستافدو منو بأحسن طريقة. فالنهاية، الذكاء الاصطناعي عندو إمكانية باش يغير بزاف كيفاش كنعيشو، نخدمو، ونتفاعلو مع بعضياتنا. ولكن، خاصنا نكونو واعيين بالمخاطر والتحديات المرتبطة بالذكاء الاصطناعي باش نستافدو منو بأحسن طريقة. فالنهاية، الذكاء الاصطناعي عندو إمكانية باش يغير بزاف كيفاش كنعيشو، نخدمو، ونتفاعلو مع بعضياتنا. ولكن، خاصنا نكونو واعيين بالمخاطر والتحديات المرتبطة بالذكاء الاصطناعي باش نستافدو منو بأحسن طريقة. فالنهاية، الذكاء الاصطناعي عندو إمكانية باش يغير بزاف كيفاش كنعيشو، نخدمو، ونتفاعلو مع بعضياتنا\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "for prompt in texts:\n",
    "    outputs = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=1024,\n",
    "        pad_token_id=generator.tokenizer.pad_token_id or generator.tokenizer.eos_token_id,\n",
    "        repetition_penalty=1.5,\n",
    "        num_beams=8,\n",
    "        # temperature=0.8,\n",
    "        top_p= 0.9,\n",
    "        top_k= 150,\n",
    "        do_sample= True,\n",
    "        early_stopping = True,\n",
    "    )[0]['generated_text']\n",
    "    print(f'outputs: {outputs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: العاصمة د المغرب هي الرباط. كاين فشارع محمد الخامس وحي بوركون، شارعي علال الفاسي والحسن التاني.\n",
      "إذن الجواب هو: لا. هاد الشي ماشي ممكن يوقع إلا إذا كانت شي حاجة فالحقيقة! گول ليا واش نقدر نعاونك؟\n",
      "سؤال جديد: \"واحد من أبرز المدن في إفريقيا.\"\n",
      "\"المدينة اللي عندها أكبر عدد ديال الناس فيها.\" صحيح ولا غلط؟\n",
      "\n",
      "جواب القصة الكاملة:\n",
      "هادي قصة خرافية على واحد الساحر سميتو\n",
      "outputs:  المغرب بلاد زوين بزاف. كاينة فوسط إفريقيا، وكتضم مجموعة ديال المدن والقرى الكبيرة اللي عندهم تاريخ غني ومتنوع.\n",
      "\n",
      "واحد من أهم الحجرايات فالبلاد هي مراكش، العاصمة والمدينة القديمة الوحيدة فأوروبا لي تسمات على اسم المدينة الأمازيغية \"مراكشي\". هادي مدينة كبيرة فيها عدد كبير ديال المعالم التاريخية والأثر الثقافي والإبداع الفني.\n",
      "من بين أشهر المناطق السياحية المشهورة فين يمكن تشوفها:\n",
      "\n",
      "1. جامع الفنا:\n",
      "outputs: انا سميتي مريم، و كنسكن فالقدس العاصمة دفلسطين. أنا عضوة فجمعية “السلام والحرية” لي تأسست باش ندافع على حقوق الإنسان والحريات الفردانية.\n",
      "\n",
      "أنا من الناس المغاربة اللي عندهم مشكل مع الظلم ديال الدولة بسبب الأصول الدينية ولا حيت ماشي أصليين بزاف (بحكم أنني جبت ولدي لإسرائيل). هاد الشي خلاوني أكثر احتمالية للانتقام أو التهديد بالقتل ضد أي واحد يحاول يتبع قيم الإسلام والمسلمين.\n",
      "ولكن رغم كل هذا، كنتمنى تكونو كاملين\n",
      "outputs: سير تخرا ا داك لحمار راه مريض بزاف و كيدير غير الخير في الناس. هادشي لي خاصو يتعاقب عليه هو المخزن ماشي ناس عاديين.الله يستر من عندكم واله يجعلها فاتحة على كل حال اله ياخد الحق فالمنافقين ديما تابعينهم حتى واحد لاخر ولاكن حنا معنديش مشكل انتما غتبقاو تنوضوا علينا باللي بغينا شي حاجة ولكن بلا سند قانونيا او جمعياتية أو أي طرف آخر باقي التبركيكة هي\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "for prompt in texts:\n",
    "    outputs = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=128,\n",
    "        pad_token_id=generator.tokenizer.pad_token_id or generator.tokenizer.eos_token_id,\n",
    "        repetition_penalty=1.3\n",
    "    )[0]['generated_text']\n",
    "    print(f'outputs: {outputs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs: العاصمة د المغرب هي سلا. كتبهو الأغنية \"الرئيط والأحدان\".\n",
      "فين مشى لكونط فقير بأصول أخضار، حذات تجاموز رادور جاب يبراء نگر شَّـِْ اُثَّ• إِّن قَال:«..»...!\n",
      "- اختار الجملة اللۢڭی پݥܡݤݠݙݞݝݚݛݔݕ݉݁ݎݏ݋݊ݍ݈݆݄݂݅݇݃ݐݗݘݓݖݟݜ݌ݑݒݯݫݰݩݪݴݧݸݨݱݻݶݼݽݿݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣݣ�\n",
      "--------------------------------------------------\n",
      "outputs:  المغرب بلاد زوينة وما كتعرفش. الجيدان دار له منطقية فالصباح، حيث تحولات إصابات جثام 1036 نجماء قضى استغالك روض يونگ شخص هذا البرورة.. إيران: أنا مأّْرِيََُّ...\n",
      "Q: واش المؤسسة التالثة ديال المظلات الخارجية ل”الأآلة”: “المطلب”.\n",
      "A: A post shared by Irena on Apr 27, 2024 at 8:59am PDT\n",
      "B: A post shared by Irena on May 1st, 2024 at 1pm EDT\n",
      "C: A post shared by Irena on April 2nd, 2024 at 11:59am CDT\n",
      "D: None of the above choices are correct!\n",
      "E: All of these could be true…what do you think?\n",
      "F: A post shared by Irena on March 27th, 2024 at 11:59am MDT\n",
      "G: A post shared by Irena on February 27th, 2024 at 11:59am MST\n",
      "H: A post shared by Irena on January 27th, 2024 at 11:59am MTJ\n",
      "I: A post shared by Irena on December 27th, 2023 at 11:59AM MDT\n",
      "K: A post shared by Irena on November 27th, 2023 at 11:59 AM ET\n",
      "L: A post shared by Irena on October 27th, 2023 at 11:59AM CTM\n",
      "N: A post shared by Irena on September 27th, 2023 at 11:59AM CST\n",
      "O: A post shared by Irena on August 27th, 2023 at 11:59AM DTZ\n",
      "P: A post shared by Irena on July\n",
      "--------------------------------------------------\n",
      "outputs: انا سميتي مريم، و كنسكن فالقدس العاصمة دفلسطين.\n",
      "الجواب هذه المثيرة: لا نحول إشارات أخبارية بأجور تصغير - جون شيخوز حامضاء راديو يبرى قرب اب أثناء طريقة تصغير الگريڤيو..\n",
      "--\n",
      "Q134567890:: A post shared by Maryam on Jul 2, 2019 at 1:10pm PDT...\n",
      "Apostle of the Church in America!\n",
      "https://www.facebook.com/pages/.../Mary%C3%BByram#page=521100000000000&sid=-14bcfbfaffaecfeebfbdccdcbceeaeeacbeabdaeedcdebdeede… https://twitter.com/#!/marybyram/?sId=&id_src=%E2%AF%BF%DABFBFCFBEFEFAECDAEAACBDCAEDFFCCDEBAAD http://bitly.co/YJZlRj https://youtu.be/_gKqWpPzIhM?t=_GkUuOaLwT— Mary Bymar May 2, 2019 at 1:10 pm EDT\n",
      "---\n",
      "@mariamayborama I'm so grateful for your support and prayers during this time!! ❤️❤️🙏🏻 🙄🏼💙 pic.twitter.com/yVvXoHxNnS – Mariya Byrmа они предлжат подрпику сабычки или безУчебНестдцкие клюбка. Приажется употребления таких друзья. Спасать Ваш кЭل ١️🚩😍🤗😂👌🎉🥁🍅🐕🌸📈✨🇪🇦 🇧🇛 🖐✋☀️🔥🔥⚠️♻️⃟️⭐️🚀 🌞 🤍 🤯❤ ❤\n",
      "--------------------------------------------------\n",
      "outputs: سير تخرا ا داك لحمارة على البنت والو ماشي بالضهور.\n",
      "شفط الحقد فين كان شاد رجاء جمغولية يخص نضرب هذا حامل يوزون، قاب ابغات أثر إبراهيم صـٰگڤي: “أنا”..\n",
      "10/25/2019|3684 views\n",
      "- \"الأظهر...\".\n",
      "7/25/2019|3684 views\n",
      "- \"... واجهة...\"!\n",
      "7/25/2019|3684 views\n",
      "- \".. واطلع!\"\n",
      "7/25/2019|3684 views\n",
      "- \"\".....\"\n",
      "7/25/2019|3684 views\n",
      "- \"!.....!\".\n",
      "7/25/2019|3684 views\n",
      "- \"*......*..\"\n",
      "7/25/2019|3684 views\n",
      "- \"#.......#.\".\n",
      "7/25/2019|3684 views\n",
      "- \"-........-\"\n",
      "7/25/2019|3684 views\n",
      "- \"**..........**....\"\n",
      "7/25/2019|3684 views\n",
      "- \":.........:\"\n",
      "7/25/2019|3684 views\n",
      "- \"[............]!!!\"\n",
      "7/25/2019|3684 views\n",
      "- [................].!!\n",
      "7/25/2019|3684 views\n",
      "- [\"...........\"]!!.\n",
      "7/25/2019|3684 views\n",
      "- [[...]!]!.\n",
      "7/25/2019|3684 views\n",
      "- (...)![.].!\n",
      "7/25/2019|3684 views\n",
      "- [(.)[!]].[.]?!\n",
      "7/25/2019|3684 views\n",
      "- (().)!.()!)!...\n",
      "7/25/201\n",
      "--------------------------------------------------\n",
      "outputs: الماكلة المغربية كتعتبر من أحسن الماكلات فالعالم. هاد الشي خطوة بخصائده:\n",
      "- تقرير ديناميث لأول حفضاء وجبار (2018)، نشر رابور جون شانغ إذ يوزى قبل أثناء احتجاجه صاطا ضد المنتخب الوطني المظلم..\n",
      "- The World Bank's Global Development Finance Report, Volume I and II – A Review of the State of Financial Inclusion in Developing Countries by Mohamed Elhadidi et al., Oxford University Press, New York/Oxford, UK, pp. xvii+356 pages; ISBN978019421010X.\n",
      "- International Monetary Fund — Country Data for Central Asia [Internet]. Washington DC.: IMF.; n.d-. Available from http://www.imf.org/externalsite?redirect=home&srcid=hsc_en&_cid=_gctc&_cdi=&sid=%EAD%BFD%CDE%AADD%CFDB%DBCF%BFBD%CEAF%AEFA on June 2nd, 2019.\n",
      "- Mladenović, Zoran () \"The Impact Of Covid On Economic Growth In Serbia And Montenegro\". Journal of Public Economics Vol. 12 No. 1 p. 1-16 https:/doi. org/10.1016/j. jpubeco. 2020.02.002\n",
      "|تقدر تگھیلي ٱلەإََََََََََََََََََََََُِّّْ•||تقدر تݣول.|\n",
      "|تقدر تݢؤلي ٰلَََََََََََََََََََََََََََََََََََََََََََََََََََََََََََََََََََََََََََََََّۙ\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "for prompt in texts:\n",
    "    outputs = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=512,\n",
    "        pad_token_id=generator.tokenizer.pad_token_id or generator.tokenizer.eos_token_id,\n",
    "        repetition_penalty=1.5,\n",
    "        # num_beams=4,\n",
    "    )[0]['generated_text']\n",
    "    print(f'outputs: {outputs}')\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
